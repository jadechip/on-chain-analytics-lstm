{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metrics",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jadechip/on-chain-analytics-lstm/blob/master/metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HgLDnmnGbg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import json\n",
        "import requests\n",
        "import functools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFxN7dkbJsrG",
        "colab_type": "text"
      },
      "source": [
        "## Bitcoin price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foTVepq3Vm0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_request(url, *args):\n",
        "  print(url(*args))\n",
        "  return requests.get(url(*args))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l11fDubusSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start      = 20100718\n",
        "end        = 20180429\n",
        "params     = \"PriceUSD\"\n",
        "url        = lambda params: f\"https://community-api.coinmetrics.io/v2/assets/btc/metricdata?metrics={params}&start={start}&end={end}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8fm4VPiuE-7",
        "colab_type": "code",
        "outputId": "2e306434-6383-418c-83fc-bb585a7c73a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "response = make_request(url, \"PriceUSD\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://community-api.coinmetrics.io/v2/assets/btc/metricdata?metrics=PriceUSD&start=20100718&end=20180429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWRIuudJFsIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json = response.json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWT7fFpn0yVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_df = pd.DataFrame(json[\"metricData\"][\"series\"])\n",
        "price_df[\"values\"] = price_df[\"values\"].apply(lambda x: x[0])\n",
        "price_df[\"values\"] = price_df[\"values\"].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te6Gl31rr9eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_df['time'] = pd.to_datetime(price_df['time'])\n",
        "price_df['time'] = price_df['time'].dt.strftime('%d-%m-%Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzquzcjhYZeB",
        "colab_type": "code",
        "outputId": "cc9a3b70-dacb-4e66-9b35-4e42925196a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "price_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18-07-2010</td>\n",
              "      <td>0.085840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19-07-2010</td>\n",
              "      <td>0.080800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20-07-2010</td>\n",
              "      <td>0.074736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21-07-2010</td>\n",
              "      <td>0.079193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22-07-2010</td>\n",
              "      <td>0.058470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         time    values\n",
              "0  18-07-2010  0.085840\n",
              "1  19-07-2010  0.080800\n",
              "2  20-07-2010  0.074736\n",
              "3  21-07-2010  0.079193\n",
              "4  22-07-2010  0.058470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9FR38EHJxj-",
        "colab_type": "text"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4TXYlYsJ6PH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start      = 1279324800\n",
        "end        = 1524960000\n",
        "metrics_df = pd.DataFrame()\n",
        "api_key    = \"5a0cf8d7-d14a-44f4-b063-a76807cd5340\"\n",
        "base       = \"https://api.glassnode.com/v1\"\n",
        "url        = lambda api_key: f\"{endpoint}?api_key={api_key}&a=BTC&s={start}&u={end}\"\n",
        "endpoints  = {\n",
        "  \"dormancy\" : f\"{base}/metrics/indicators/average_dormancy\",\n",
        "  \"velocity\" : f\"{base}/metrics/indicators/velocity\",\n",
        "  \"nvts\"     : f\"{base}/metrics/indicators/nvts\",\n",
        "  \"sopr\"     : f\"{base}/metrics/indicators/sopr\",\n",
        "  \"mvrv\"     : f\"{base}/metrics/market/mvrv\" \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmDCxDMKTRd",
        "colab_type": "code",
        "outputId": "9e110b85-e602-4c96-d571-4a67f5291df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for name, endpoint in endpoints.items():\n",
        "  response = make_request(url, api_key)\n",
        "  tmp = pd.read_json(response.content, convert_dates=[\"t\"], date_unit=\"s\")\n",
        "  tmp.columns = [\"date\", name]\n",
        "  diff = tmp.columns.difference(metrics_df.columns)\n",
        "  metrics_df = pd.concat([metrics_df, tmp[diff]], axis=1, sort=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://api.glassnode.com/v1/metrics/indicators/average_dormancy?api_key=5a0cf8d7-d14a-44f4-b063-a76807cd5340&a=BTC&s=1279324800&u=1524960000\n",
            "https://api.glassnode.com/v1/metrics/indicators/velocity?api_key=5a0cf8d7-d14a-44f4-b063-a76807cd5340&a=BTC&s=1279324800&u=1524960000\n",
            "https://api.glassnode.com/v1/metrics/indicators/nvts?api_key=5a0cf8d7-d14a-44f4-b063-a76807cd5340&a=BTC&s=1279324800&u=1524960000\n",
            "https://api.glassnode.com/v1/metrics/indicators/sopr?api_key=5a0cf8d7-d14a-44f4-b063-a76807cd5340&a=BTC&s=1279324800&u=1524960000\n",
            "https://api.glassnode.com/v1/metrics/market/mvrv?api_key=5a0cf8d7-d14a-44f4-b063-a76807cd5340&a=BTC&s=1279324800&u=1524960000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za9CQ2Iyci_x",
        "colab_type": "text"
      },
      "source": [
        "### Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92gL2gAUd7nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics_df[\"target_price\"] = price_df[\"values\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPmsY5WuZVak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics_df = metrics_df.set_index(\"date\", drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB2MwZG1Zd-b",
        "colab_type": "code",
        "outputId": "16af69bb-027b-479e-fe76-5da70527fadd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "metrics_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dormancy</th>\n",
              "      <th>velocity</th>\n",
              "      <th>nvts</th>\n",
              "      <th>sopr</th>\n",
              "      <th>mvrv</th>\n",
              "      <th>target_price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-07-17</th>\n",
              "      <td>17.557391</td>\n",
              "      <td>0.009522</td>\n",
              "      <td>50.456801</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.085840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-18</th>\n",
              "      <td>37.898148</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>65.719591</td>\n",
              "      <td>1.174760</td>\n",
              "      <td>1.299792</td>\n",
              "      <td>0.080800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-19</th>\n",
              "      <td>8.009980</td>\n",
              "      <td>0.016157</td>\n",
              "      <td>91.505617</td>\n",
              "      <td>1.318536</td>\n",
              "      <td>1.813274</td>\n",
              "      <td>0.074736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-20</th>\n",
              "      <td>2.325436</td>\n",
              "      <td>0.011241</td>\n",
              "      <td>79.848213</td>\n",
              "      <td>1.090517</td>\n",
              "      <td>1.584801</td>\n",
              "      <td>0.079193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-21</th>\n",
              "      <td>23.594423</td>\n",
              "      <td>0.010933</td>\n",
              "      <td>70.508828</td>\n",
              "      <td>1.065532</td>\n",
              "      <td>1.398245</td>\n",
              "      <td>0.058470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             dormancy  velocity       nvts      sopr      mvrv  target_price\n",
              "date                                                                        \n",
              "2010-07-17  17.557391  0.009522  50.456801  1.000000  1.000000      0.085840\n",
              "2010-07-18  37.898148  0.012926  65.719591  1.174760  1.299792      0.080800\n",
              "2010-07-19   8.009980  0.016157  91.505617  1.318536  1.813274      0.074736\n",
              "2010-07-20   2.325436  0.011241  79.848213  1.090517  1.584801      0.079193\n",
              "2010-07-21  23.594423  0.010933  70.508828  1.065532  1.398245      0.058470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmG5s8F_eU8E",
        "colab_type": "text"
      },
      "source": [
        "### Test-Training split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8rUZ8DXGab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = lambda df: (df - df.mean()) / (df.max() - df.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9up_58LseZkl",
        "colab_type": "code",
        "outputId": "23b112d1-c74b-43c8-b76f-54e3e2bee4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_data, validation_data = train_test_split(metrics_df, test_size=0.2, shuffle=False)\n",
        "validation_data, testing_data = train_test_split(validation_data, test_size=0.5, shuffle=False)\n",
        "\n",
        "print(f\"Training data size: {training_data.shape}\",\n",
        "      f\"Validation data size: {validation_data.shape}\",\n",
        "      f\"Testing data size: {testing_data.shape}\")\n",
        "\n",
        "data = {\n",
        "  \"training\" : training_data,\n",
        "  \"validation\" : validation_data,\n",
        "  \"testing\" : testing_data,\n",
        "}\n",
        "training_data = normalize(training_data)\n",
        "validation_data = normalize(validation_data)\n",
        "testing_data = normalize(testing_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data size: (2274, 6) Validation data size: (284, 6) Testing data size: (285, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D8oyfoBaGSu",
        "colab_type": "text"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkOSuPh9XY49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"training\"] = normalize(data[\"training\"])\n",
        "data[\"validation\"] = normalize(data[\"validation\"])\n",
        "data[\"testing\"] = normalize(data[\"testing\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mzhKYjIaKJa",
        "colab_type": "code",
        "outputId": "2e00c79c-0d16-4ad0-c4ee-7775fb00cfa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data[\"training\"].head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dormancy</th>\n",
              "      <th>velocity</th>\n",
              "      <th>nvts</th>\n",
              "      <th>sopr</th>\n",
              "      <th>mvrv</th>\n",
              "      <th>target_price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-07-17</th>\n",
              "      <td>0.056365</td>\n",
              "      <td>-0.024932</td>\n",
              "      <td>0.175394</td>\n",
              "      <td>-0.011233</td>\n",
              "      <td>-0.112489</td>\n",
              "      <td>-0.197668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-18</th>\n",
              "      <td>0.154275</td>\n",
              "      <td>-0.024165</td>\n",
              "      <td>0.264575</td>\n",
              "      <td>0.128719</td>\n",
              "      <td>-0.068433</td>\n",
              "      <td>-0.197673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-19</th>\n",
              "      <td>0.010409</td>\n",
              "      <td>-0.023438</td>\n",
              "      <td>0.415242</td>\n",
              "      <td>0.243857</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>-0.197678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-20</th>\n",
              "      <td>-0.016954</td>\n",
              "      <td>-0.024545</td>\n",
              "      <td>0.347128</td>\n",
              "      <td>0.061255</td>\n",
              "      <td>-0.026549</td>\n",
              "      <td>-0.197674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-21</th>\n",
              "      <td>0.085424</td>\n",
              "      <td>-0.024614</td>\n",
              "      <td>0.292558</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>-0.053964</td>\n",
              "      <td>-0.197692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            dormancy  velocity      nvts      sopr      mvrv  target_price\n",
              "date                                                                      \n",
              "2010-07-17  0.056365 -0.024932  0.175394 -0.011233 -0.112489     -0.197668\n",
              "2010-07-18  0.154275 -0.024165  0.264575  0.128719 -0.068433     -0.197673\n",
              "2010-07-19  0.010409 -0.023438  0.415242  0.243857  0.007027     -0.197678\n",
              "2010-07-20 -0.016954 -0.024545  0.347128  0.061255 -0.026549     -0.197674\n",
              "2010-07-21  0.085424 -0.024614  0.292558  0.041247 -0.053964     -0.197692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUS3SPqgDXW8",
        "colab_type": "code",
        "outputId": "8e0eb3c0-b51b-4548-ff7b-e2ba9fc04344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data[\"validation\"].head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dormancy</th>\n",
              "      <th>velocity</th>\n",
              "      <th>nvts</th>\n",
              "      <th>sopr</th>\n",
              "      <th>mvrv</th>\n",
              "      <th>target_price</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-10-07</th>\n",
              "      <td>-0.138942</td>\n",
              "      <td>0.032624</td>\n",
              "      <td>-0.124311</td>\n",
              "      <td>-0.100253</td>\n",
              "      <td>-0.324395</td>\n",
              "      <td>-0.293851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-08</th>\n",
              "      <td>-0.152245</td>\n",
              "      <td>0.052656</td>\n",
              "      <td>-0.124892</td>\n",
              "      <td>-0.095180</td>\n",
              "      <td>-0.320336</td>\n",
              "      <td>-0.294784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-09</th>\n",
              "      <td>-0.166743</td>\n",
              "      <td>0.138148</td>\n",
              "      <td>-0.133353</td>\n",
              "      <td>-0.111686</td>\n",
              "      <td>-0.322217</td>\n",
              "      <td>-0.294367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-10</th>\n",
              "      <td>-0.130327</td>\n",
              "      <td>0.089605</td>\n",
              "      <td>-0.136278</td>\n",
              "      <td>-0.101512</td>\n",
              "      <td>-0.322193</td>\n",
              "      <td>-0.283805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-10-11</th>\n",
              "      <td>-0.083614</td>\n",
              "      <td>0.115514</td>\n",
              "      <td>-0.119162</td>\n",
              "      <td>-0.036770</td>\n",
              "      <td>-0.303636</td>\n",
              "      <td>-0.286513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            dormancy  velocity      nvts      sopr      mvrv  target_price\n",
              "date                                                                      \n",
              "2016-10-07 -0.138942  0.032624 -0.124311 -0.100253 -0.324395     -0.293851\n",
              "2016-10-08 -0.152245  0.052656 -0.124892 -0.095180 -0.320336     -0.294784\n",
              "2016-10-09 -0.166743  0.138148 -0.133353 -0.111686 -0.322217     -0.294367\n",
              "2016-10-10 -0.130327  0.089605 -0.136278 -0.101512 -0.322193     -0.283805\n",
              "2016-10-11 -0.083614  0.115514 -0.119162 -0.036770 -0.303636     -0.286513"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEIo1zHlQCaH",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIhgHJmoZnZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils import data\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QrW_GzUh-Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS        = 1000\n",
        "DROPOUT       = 0.2\n",
        "DIRECTIONS    = 1\n",
        "NUM_LAYERS    = 2\n",
        "BATCH_SIZE    = 5\n",
        "OUTPUT_SIZE   = 1\n",
        "SEQ_LENGTH    = 7 # 90 day average\n",
        "NUM_FEATURES  = 5\n",
        "HIDDEN_SIZE   = 12\n",
        "LEARNING_RATE = 0.0001\n",
        "STATE_DIM     = NUM_LAYERS * DIRECTIONS, BATCH_SIZE, HIDDEN_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94oJ9BHotzqL",
        "colab_type": "text"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMHtPgmOG748",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxnsAPGKgH-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_xy_pairs(csv_file, seq_length, batch_size):\n",
        "#   target = \"target_price\"\n",
        "#   features = [\"dormancy\", \"velocity\", \"nvts\", \"sopr\", \"mvrv\"]\n",
        "#   data_length = len(csv_file)\n",
        "#   for idx in range(data_length - (seq_length * batch_size)):\n",
        "#     x = csv_file[idx:idx + (seq_length * batch_size)][features].values\n",
        "#     y = csv_file[idx + (seq_length * batch_size):idx + (seq_length * batch_size) + batch_size][target].values\n",
        "#     yield (x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuqBa3eQEfZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetricsDataset(Dataset):\n",
        "    \"\"\"Metrics dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, seq_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "        \"\"\"\n",
        "        self.csv_file = csv_file\n",
        "        self.target = \"target_price\"\n",
        "        self.features = [\"dormancy\", \"velocity\", \"nvts\", \"sopr\", \"mvrv\"]\n",
        "        \n",
        "        self.seq_length = seq_length\n",
        "        self.data_length = len(csv_file)\n",
        "\n",
        "        self.metrics = self.create_xy_pairs()\n",
        "\n",
        "    def create_xy_pairs(self):\n",
        "        pairs = []\n",
        "        for idx in range(self.data_length - self.seq_length):\n",
        "            x = self.csv_file[idx:idx + self.seq_length][self.features].values\n",
        "            y = self.csv_file[idx + self.seq_length:idx + self.seq_length + 1][self.target].values\n",
        "            pairs.append((x, y))\n",
        "        return pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metrics)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.metrics[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt7wb9wza8CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'batch_size': BATCH_SIZE,\n",
        "          'shuffle': False,\n",
        "          'drop_last': True, # Disregard last incomplete batch\n",
        "          'num_workers': 4}\n",
        "\n",
        "training_ds = MetricsDataset(training_data, SEQ_LENGTH)\n",
        "training_dl = DataLoader(training_ds, **params)\n",
        "\n",
        "validation_ds = MetricsDataset(validation_data, SEQ_LENGTH)\n",
        "validation_dl = DataLoader(validation_ds, **params)\n",
        "\n",
        "testing_ds = MetricsDataset(testing_data, SEQ_LENGTH)\n",
        "testing_dl = DataLoader(testing_ds, **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1bMo6jB_O50",
        "colab_type": "text"
      },
      "source": [
        "### Initialize model, criterion and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DNCrlW2W30n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer to accelerator\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZveTUfuW-Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, state_dim, output_size, dropout_prob):\n",
        "    super(LSTM, self).__init__()\n",
        "\n",
        "    self.state_dim = state_dim\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def init_hidden_states(self):\n",
        "    return (torch.zeros(self.state_dim).to(device), torch.zeros(self.state_dim).to(device))\n",
        "\n",
        "  def forward(self, x, states):\n",
        "    x, (h, c) = self.lstm(x, states)\n",
        "    out = self.linear(x)\n",
        "    return out, (h, c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjenlKh1jsiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM(\n",
        "    NUM_FEATURES,\n",
        "    HIDDEN_SIZE,\n",
        "    NUM_LAYERS,\n",
        "    (NUM_LAYERS * DIRECTIONS, BATCH_SIZE, HIDDEN_SIZE),\n",
        "    OUTPUT_SIZE,\n",
        "    DROPOUT\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.linear.parameters(), lr=LEARNING_RATE, weight_decay=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w48uB_hYan9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(epoch, min_val_loss, model_state, opt_state):\n",
        "  print(f\"New minimum reached at epoch #{epoch + 1}, saving model state...\")\n",
        "  checkpoint = {\n",
        "    'epoch': epoch + 1,\n",
        "    'min_val_loss': min_val_loss,\n",
        "    'model_state': model_state,\n",
        "    'opt_state': opt_state,\n",
        "  }\n",
        "  torch.save(checkpoint, \"./model_state.pt\")\n",
        "\n",
        "\n",
        "def load_checkpoint(path, model, optimizer):\n",
        "    # load check point\n",
        "    checkpoint = torch.load(path)\n",
        "    min_val_loss = checkpoint[\"min_val_loss\"]\n",
        "    model.load_state_dict(checkpoint[\"model_state\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"opt_state\"])\n",
        "    return model, optimizer, checkpoint[\"epoch\"], min_val_loss\n",
        "\n",
        "\n",
        "def training(model, epochs, validate_every=2):\n",
        "\n",
        "  training_losses = []\n",
        "  validation_losses = []\n",
        "\n",
        "  min_validation_loss = np.Inf\n",
        "\n",
        "  # Set to train mode\n",
        "  model.train()\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    # Initialize hidden and cell states with dimension:\n",
        "    # (num_layers * num_directions, batch, hidden_size)\n",
        "    states = model.init_hidden_states()\n",
        "    running_training_loss = 0.0\n",
        "\n",
        "    # Begin training\n",
        "    for idx, (x_batch, y_batch) in enumerate(training_dl):\n",
        "          \n",
        "      # Convert to Tensors\n",
        "      x_batch = x_batch.float().to(device)\n",
        "      y_batch = y_batch.float().to(device)\n",
        "      \n",
        "      # Truncated Backpropagation\n",
        "      states = [state.detach() for state in states]          \n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Make prediction\n",
        "      output, states = model(x_batch, states)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = criterion(output[:, -1, :], y_batch)\n",
        "      loss.backward()\n",
        "      running_training_loss += loss.item()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "      optimizer.step()\n",
        "\n",
        "      # print(f\"Epoch {epoch + 1}/{epochs}\", \n",
        "      #       f\"Index: {idx + 1}\",\n",
        "      #       f\"Loss: {loss.item()}\")\n",
        "        \n",
        "    # Average loss across timesteps\n",
        "    training_losses.append(running_training_loss / len(training_dl))\n",
        "        \n",
        "    if epoch % validate_every == 0:\n",
        "\n",
        "      # Set to eval mode\n",
        "      model.eval()\n",
        "\n",
        "      validation_states = model.init_hidden_states()\n",
        "      running_validation_loss = 0.0\n",
        "\n",
        "      for idx, (x_batch, y_batch) in enumerate(validation_dl):\n",
        "\n",
        "        # Convert to Tensors\n",
        "        x_batch = x_batch.float().to(device)\n",
        "        y_batch = y_batch.float().to(device)\n",
        "      \n",
        "        validation_states = [state.detach() for state in validation_states]\n",
        "        \n",
        "        output, validation_states = model(x_batch, validation_states)\n",
        "        validation_loss = criterion(output[:, -1, :], y_batch)\n",
        "        running_validation_loss += validation_loss.item()\n",
        "\n",
        "        # print(f\"Epoch {epoch + 1}/{epochs}\", \n",
        "        #       f\"Index: {idx + 1}\",\n",
        "        #       f\"Validation loss: {validation_loss.item()},\")\n",
        "        \n",
        "    validation_losses.append(running_validation_loss / len(validation_dl))\n",
        "    # Reset to training mode\n",
        "    model.train()\n",
        "\n",
        "    is_best = running_validation_loss / len(validation_dl) < min_validation_loss\n",
        "\n",
        "    if is_best:\n",
        "      min_validation_loss = running_validation_loss / len(validation_dl)\n",
        "      save_checkpoint(epoch + 1, min_validation_loss, model.state_dict(), optimizer.state_dict())\n",
        "        \n",
        "\n",
        "\n",
        "  # Visualize loss\n",
        "  epoch_count = range(1, len(training_losses) + 1)\n",
        "  plt.plot(epoch_count, training_losses, 'r--')\n",
        "  plt.legend(['Training Loss'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()\n",
        "\n",
        "  val_epoch_count = range(1, len(validation_losses) + 1)\n",
        "  plt.plot(val_epoch_count, validation_losses, 'b-')\n",
        "  plt.legend(['Validation loss'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFl5ChymdSXt",
        "colab_type": "code",
        "outputId": "12678c28-9155-41dd-b7a5-91ff88807394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "training(model, 50)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:02<02:09,  2.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New minimum reached at epoch #2, saving model state...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3/50 [00:07<01:55,  2.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New minimum reached at epoch #4, saving model state...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:11<01:46,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New minimum reached at epoch #6, saving model state...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 7/50 [00:16<01:40,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New minimum reached at epoch #8, saving model state...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 9/50 [00:20<01:37,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New minimum reached at epoch #10, saving model state...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [01:57<00:00,  2.30s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC5uUUCFgcvc3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPLOg6zg6nlEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oghu8-XUKeFK",
        "colab_type": "code",
        "outputId": "4e580d4a-c311-4e55-c808-2d38428e099b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "path = \"./model_state.pt\"\n",
        "model, optimizer, start_epoch, valid_loss_min = load_checkpoint(path, model, optimizer)\n",
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", optimizer)\n",
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"valid_loss_min = \", valid_loss_min)\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model =  LSTM(\n",
            "  (lstm): LSTM(5, 12, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (linear): Linear(in_features=12, out_features=1, bias=True)\n",
            ")\n",
            "optimizer =  AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.0001\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "start_epoch =  10\n",
            "valid_loss_min =  0.075432852239729\n",
            "valid_loss_min = 0.075433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB4123Z5sLKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_states = model.init_hidden_states()\n",
        "predictions = []\n",
        "for idx, (x_batch, _) in enumerate(testing_dl):\n",
        "  with torch.no_grad():\n",
        "    x_batch = x_batch.float().to(device)\n",
        "    testing_states = [state.detach() for state in testing_states]\n",
        "    output, testing_states = model(x_batch, testing_states)\n",
        "    predictions.append(output[:, -1, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWuKScf4wO4J",
        "colab_type": "code",
        "outputId": "fca654ff-1bac-4296-ca57-74a062dc8800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs2_rbXv4Alj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cb83a3b2-645f-4907-d5e5-042fd080125c"
      },
      "source": [
        "predictions[-1]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0052],\n",
              "        [ 0.0032],\n",
              "        [-0.0028],\n",
              "        [-0.0086],\n",
              "        [-0.0054]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z6pNrlxauP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "a959e532-52b1-44c7-a4d4-1be88f6aae8b"
      },
      "source": [
        "epoch_count = range(1, len(predictions) + 1)\n",
        "plt.plot(epoch_count, predictions, 'r--')\n",
        "plt.legend(['Predictions'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5b83ade17bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2794\u001b[0m     return gca().plot(\n\u001b[1;32m   2795\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2796\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \"\"\"\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIaxnf53xkJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ostKfdw-tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tVuBbXGS5tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_dim = (NUM_LAYERS * DIRECTIONS, BATCH_SIZE, HIDDEN_SIZE)\n",
        "\n",
        "def make_predictions(input, num_predictions):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for i in range(num_predictions):\n",
        "        with torch.no_grad():\n",
        "\n",
        "\n",
        "        \n",
        "          states = (torch.zeros(state_dim).to(device), torch.zeros(state_dim).to(device))\n",
        "          predictions.append(model(input, states).item())\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAPJesXyyEt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# note: batch normalization instead of general normalization\n",
        "\n",
        "# Make 1 prediction\n",
        "\n",
        "test_window = test_data[:SEQ_LENGTH]\n",
        "test_tensor = torch.tensor(test_window.values).float()\n",
        "test_batch = test_tensor.view(1, SEQ_LENGTH).to(device)\n",
        "make_predictions(test_tensor, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGlplT533V7T",
        "colab_type": "code",
        "outputId": "c2075b48-6556-4a1c-9c0c-ec5991a9792f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.from_numpy(testing_data.iloc[50][[\"dormancy\", \"velocity\", \"nvts\", \"sopr\", \"mvrv\"]].values).float()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6.3115,  0.0595, 10.0556,  1.0050,  1.8457])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yZdSCM-uSPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction\n",
        "\n",
        "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
        "  prediction_seqs = []\n",
        "  for i in range(int(len(data)/prediction_len)):\n",
        "    curr_frame = data[i*prediction_len]\n",
        "    predicted = []\n",
        "    with torch.no_grad():\n",
        "      for j in range(prediction_len):\n",
        "        predicted.append(model(curr_frame[newaxis,:,:])[0,0])\n",
        "        curr_frame = curr_frame[1:]\n",
        "        curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
        "      prediction_seqs.append(predicted)\n",
        "  return prediction_seqs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYf9ozvzYt3",
        "colab_type": "code",
        "outputId": "5ea5025e-9217-4d48-a5c0-6133cd88a27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "predict_sequences_multiple(model, testing_data, SEQ_LENGTH, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-9e401e8ecb75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_sequences_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-4931f9276f19>\u001b[0m in \u001b[0;36mpredict_sequences_multiple\u001b[0;34m(model, data, window_size, prediction_len)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprediction_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcurr_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprediction_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdP8SIkE_YNh",
        "colab_type": "code",
        "outputId": "b3e12195-d278-407a-eb8b-31a2991f52eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.eval()\n",
        "\n",
        "state_dim = (NUM_LAYERS * DIRECTIONS, BATCH_SIZE, HIDDEN_SIZE)\n",
        "validation_states = (torch.zeros(state_dim).to(device), torch.zeros(state_dim).to(device))\n",
        "running_validation_loss = 0.0\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for idx, (x_batch, y_batch) in enumerate(tqdm(validation_dl)):\n",
        "\n",
        "        # Convert to Tensors\n",
        "        x_batch = x_batch.float().to(device)\n",
        "        y_batch = y_batch.float().to(device)\n",
        "      \n",
        "        validation_states = [state.detach() for state in validation_states]\n",
        "        \n",
        "        output, validation_states = model(x_batch, validation_states)\n",
        "        import pdb; pdb.set_trace()\n",
        "        predictions.append(output[:, -1, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/436 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> <ipython-input-34-d802e7a2c1a9>(19)<module>()\n",
            "-> predictions.append(output[:, -1, :])\n",
            "(Pdb) output\n",
            "tensor([[[0.0241],\n",
            "         [0.0118],\n",
            "         [0.0052],\n",
            "         [0.0018],\n",
            "         [0.0011],\n",
            "         [0.0009],\n",
            "         [0.0014],\n",
            "         [0.0029],\n",
            "         [0.0034],\n",
            "         [0.0047],\n",
            "         [0.0054],\n",
            "         [0.0050],\n",
            "         [0.0044],\n",
            "         [0.0041],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0046],\n",
            "         [0.0049],\n",
            "         [0.0047],\n",
            "         [0.0045],\n",
            "         [0.0041],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0040],\n",
            "         [0.0043],\n",
            "         [0.0070],\n",
            "         [0.0065],\n",
            "         [0.0056],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0054],\n",
            "         [0.0101],\n",
            "         [0.0093],\n",
            "         [0.0075],\n",
            "         [0.0088],\n",
            "         [0.0082],\n",
            "         [0.0067],\n",
            "         [0.0055],\n",
            "         [0.0054],\n",
            "         [0.0048],\n",
            "         [0.0044],\n",
            "         [0.0043],\n",
            "         [0.0041],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0043],\n",
            "         [0.0040]],\n",
            "\n",
            "        [[0.0248],\n",
            "         [0.0116],\n",
            "         [0.0044],\n",
            "         [0.0017],\n",
            "         [0.0007],\n",
            "         [0.0008],\n",
            "         [0.0023],\n",
            "         [0.0029],\n",
            "         [0.0042],\n",
            "         [0.0051],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0037],\n",
            "         [0.0037],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0046],\n",
            "         [0.0049],\n",
            "         [0.0047],\n",
            "         [0.0045],\n",
            "         [0.0041],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0040],\n",
            "         [0.0043],\n",
            "         [0.0070],\n",
            "         [0.0065],\n",
            "         [0.0056],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0054],\n",
            "         [0.0101],\n",
            "         [0.0093],\n",
            "         [0.0075],\n",
            "         [0.0088],\n",
            "         [0.0082],\n",
            "         [0.0067],\n",
            "         [0.0055],\n",
            "         [0.0054],\n",
            "         [0.0048],\n",
            "         [0.0044],\n",
            "         [0.0043],\n",
            "         [0.0041],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0038]],\n",
            "\n",
            "        [[0.0241],\n",
            "         [0.0106],\n",
            "         [0.0042],\n",
            "         [0.0013],\n",
            "         [0.0006],\n",
            "         [0.0018],\n",
            "         [0.0023],\n",
            "         [0.0037],\n",
            "         [0.0047],\n",
            "         [0.0044],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0041],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0045],\n",
            "         [0.0049],\n",
            "         [0.0047],\n",
            "         [0.0045],\n",
            "         [0.0041],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0040],\n",
            "         [0.0043],\n",
            "         [0.0070],\n",
            "         [0.0065],\n",
            "         [0.0056],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0054],\n",
            "         [0.0101],\n",
            "         [0.0093],\n",
            "         [0.0075],\n",
            "         [0.0088],\n",
            "         [0.0082],\n",
            "         [0.0067],\n",
            "         [0.0055],\n",
            "         [0.0054],\n",
            "         [0.0048],\n",
            "         [0.0044],\n",
            "         [0.0043],\n",
            "         [0.0041],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039]],\n",
            "\n",
            "        [[0.0237],\n",
            "         [0.0109],\n",
            "         [0.0041],\n",
            "         [0.0014],\n",
            "         [0.0016],\n",
            "         [0.0018],\n",
            "         [0.0031],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0045],\n",
            "         [0.0049],\n",
            "         [0.0047],\n",
            "         [0.0045],\n",
            "         [0.0041],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0040],\n",
            "         [0.0043],\n",
            "         [0.0070],\n",
            "         [0.0065],\n",
            "         [0.0056],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0054],\n",
            "         [0.0101],\n",
            "         [0.0093],\n",
            "         [0.0075],\n",
            "         [0.0088],\n",
            "         [0.0082],\n",
            "         [0.0067],\n",
            "         [0.0055],\n",
            "         [0.0054],\n",
            "         [0.0048],\n",
            "         [0.0044],\n",
            "         [0.0043],\n",
            "         [0.0041],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0035]],\n",
            "\n",
            "        [[0.0243],\n",
            "         [0.0109],\n",
            "         [0.0042],\n",
            "         [0.0024],\n",
            "         [0.0016],\n",
            "         [0.0026],\n",
            "         [0.0035],\n",
            "         [0.0035],\n",
            "         [0.0033],\n",
            "         [0.0032],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0034],\n",
            "         [0.0035],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0045],\n",
            "         [0.0049],\n",
            "         [0.0047],\n",
            "         [0.0045],\n",
            "         [0.0041],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0036],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0037],\n",
            "         [0.0036],\n",
            "         [0.0036],\n",
            "         [0.0035],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0037],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0042],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0040],\n",
            "         [0.0043],\n",
            "         [0.0070],\n",
            "         [0.0065],\n",
            "         [0.0056],\n",
            "         [0.0048],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0039],\n",
            "         [0.0038],\n",
            "         [0.0038],\n",
            "         [0.0037],\n",
            "         [0.0054],\n",
            "         [0.0101],\n",
            "         [0.0093],\n",
            "         [0.0075],\n",
            "         [0.0088],\n",
            "         [0.0082],\n",
            "         [0.0067],\n",
            "         [0.0055],\n",
            "         [0.0054],\n",
            "         [0.0048],\n",
            "         [0.0044],\n",
            "         [0.0043],\n",
            "         [0.0041],\n",
            "         [0.0041],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0043],\n",
            "         [0.0040],\n",
            "         [0.0038],\n",
            "         [0.0039],\n",
            "         [0.0035],\n",
            "         [0.0031]]], device='cuda:0')\n",
            "(Pdb) output[:, -1, :]\n",
            "tensor([[0.0040],\n",
            "        [0.0038],\n",
            "        [0.0039],\n",
            "        [0.0035],\n",
            "        [0.0031]], device='cuda:0')\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n",
            "(Pdb) exit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d802e7a2c1a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-d802e7a2c1a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUWnf5ZtuIGP",
        "colab_type": "code",
        "outputId": "d29ccf2c-3ef0-4a84-dadc-d040f5ddd353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "preds_epoch_count = range(1, len(predictions) + 1)\n",
        "plt.plot(preds_epoch_count, predictions, 'b-')\n",
        "plt.legend(['Predictions'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Predictions')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-42cf1bfa24b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds_epoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_epoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2787\u001b[0m     return gca().plot(\n\u001b[1;32m   2788\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2789\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1667\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \"\"\"\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrZ2TvzguVsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}